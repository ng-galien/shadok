#!/bin/bash

# Script de test pour les composants avancÃ©s de kind
# Usage: ./test-kind-config.sh [cluster-name]

set -euo pipefail

# Configuration
CLUSTER_NAME="${1:-shadok-dev}"

# Couleurs pour les logs
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# Test de cert-manager
test_cert_manager() {
    log_info "ğŸ” === Test de cert-manager ==="
    
    # VÃ©rifier que cert-manager est installÃ©
    if ! kubectl get namespace cert-manager --context "kind-${CLUSTER_NAME}" &> /dev/null; then
        log_error "âŒ Namespace cert-manager non trouvÃ©"
        return 1
    fi
    
    # VÃ©rifier que les pods sont en marche
    local ready_pods=$(kubectl get pods -n cert-manager --context "kind-${CLUSTER_NAME}" \
        --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l | tr -d ' ')
    
    if [ "$ready_pods" -ge 3 ]; then
        log_success "âœ… cert-manager opÃ©rationnel ($ready_pods pods)"
    else
        log_warning "âš ï¸  cert-manager partiellement opÃ©rationnel ($ready_pods pods)"
    fi
    
    # Tester la crÃ©ation d'un certificat
    kubectl apply -f - <<EOF
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  name: test-cert-temp
  namespace: default
spec:
  secretName: test-cert-temp-secret
  issuerRef:
    name: selfsigned-issuer
    kind: ClusterIssuer
  dnsNames:
  - temp-test.local
EOF
    
    # Attendre un peu et vÃ©rifier
    sleep 10
    if kubectl get certificate test-cert-temp --context "kind-${CLUSTER_NAME}" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' | grep -q "True"; then
        log_success "ğŸ”’ CrÃ©ation de certificat fonctionnelle"
    else
        log_warning "âš ï¸  CrÃ©ation de certificat en cours..."
    fi
    
    # Nettoyer
    kubectl delete certificate test-cert-temp --context "kind-${CLUSTER_NAME}" &> /dev/null || true
    kubectl delete secret test-cert-temp-secret --context "kind-${CLUSTER_NAME}" &> /dev/null || true
    
    return 0
}

# Test d'ingress-nginx avec snippets
test_ingress_nginx() {
    log_info "ğŸŒ === Test d'ingress-nginx avec snippets ==="
    
    # VÃ©rifier que ingress-nginx est installÃ©
    if ! kubectl get namespace ingress-nginx --context "kind-${CLUSTER_NAME}" &> /dev/null; then
        log_error "âŒ Namespace ingress-nginx non trouvÃ©"
        return 1
    fi
    
    # VÃ©rifier que les pods sont en marche
    local ready_pods=$(kubectl get pods -n ingress-nginx --context "kind-${CLUSTER_NAME}" \
        --selector=app.kubernetes.io/component=controller \
        --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l | tr -d ' ')
    
    if [ "$ready_pods" -gt 0 ]; then
        log_success "âœ… ingress-nginx opÃ©rationnel ($ready_pods pods)"
    else
        log_error "âŒ ingress-nginx non opÃ©rationnel"
        return 1
    fi
    
    # VÃ©rifier que les snippets sont activÃ©s
    local controller_config=$(kubectl get configmap ingress-nginx-controller -n ingress-nginx --context "kind-${CLUSTER_NAME}" -o jsonpath='{.data}' 2>/dev/null || echo "")
    
    if echo "$controller_config" | grep -q "allow-snippet-annotations"; then
        log_success "ğŸ”§ Snippets activÃ©s dans la configuration"
    else
        log_warning "âš ï¸  Configuration des snippets non dÃ©tectÃ©e"
    fi
    
    # CrÃ©er un ingress de test avec snippet
    kubectl apply -f - <<EOF
apiVersion: v1
kind: Service
metadata:
  name: test-service-temp
  namespace: default
spec:
  selector:
    app: curl-test
  ports:
  - port: 80
    targetPort: 8080
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: test-ingress-temp
  namespace: default
  annotations:
    nginx.ingress.kubernetes.io/configuration-snippet: |
      add_header X-Test-Snippet "Hello from snippet" always;
spec:
  ingressClassName: nginx
  rules:
  - host: test-snippet.local
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: test-service-temp
            port:
              number: 80
EOF
    
    sleep 5
    
    # Tester l'ingress
    if kubectl get ingress test-ingress-temp --context "kind-${CLUSTER_NAME}" &> /dev/null; then
        log_success "ğŸ“ Ingress avec snippet crÃ©Ã©"
    else
        log_warning "âš ï¸  Ã‰chec de crÃ©ation de l'ingress avec snippet"
    fi
    
    # Nettoyer
    kubectl delete ingress test-ingress-temp --context "kind-${CLUSTER_NAME}" &> /dev/null || true
    kubectl delete service test-service-temp --context "kind-${CLUSTER_NAME}" &> /dev/null || true
    
    return 0
}

# Test du Kubernetes Dashboard
test_dashboard() {
    log_info "ğŸ“Š === Test du Kubernetes Dashboard ==="
    
    # VÃ©rifier que le dashboard est installÃ©
    if ! kubectl get namespace kubernetes-dashboard --context "kind-${CLUSTER_NAME}" &> /dev/null; then
        log_error "âŒ Namespace kubernetes-dashboard non trouvÃ©"
        return 1
    fi
    
    # VÃ©rifier que les pods sont en marche
    local ready_pods=$(kubectl get pods -n kubernetes-dashboard --context "kind-${CLUSTER_NAME}" \
        --field-selector=status.phase=Running --no-headers 2>/dev/null | wc -l | tr -d ' ')
    
    if [ "$ready_pods" -gt 0 ]; then
        log_success "âœ… Kubernetes Dashboard opÃ©rationnel ($ready_pods pods)"
    else
        log_error "âŒ Kubernetes Dashboard non opÃ©rationnel"
        return 1
    fi
    
    # VÃ©rifier l'ingress du dashboard
    if kubectl get ingress kubernetes-dashboard -n kubernetes-dashboard --context "kind-${CLUSTER_NAME}" &> /dev/null; then
        log_success "ğŸŒ Ingress dashboard configurÃ©"
        
        # VÃ©rifier l'annotation du snippet
        local snippet=$(kubectl get ingress kubernetes-dashboard -n kubernetes-dashboard --context "kind-${CLUSTER_NAME}" \
            -o jsonpath='{.metadata.annotations.nginx\.ingress\.kubernetes\.io/configuration-snippet}' 2>/dev/null || echo "")
        
        if echo "$snippet" | grep -q "Authorization"; then
            log_success "ğŸ” Snippet d'auto-login configurÃ©"
        else
            log_warning "âš ï¸  Snippet d'auto-login non dÃ©tectÃ©"
        fi
    else
        log_warning "âš ï¸  Ingress dashboard non trouvÃ©"
    fi
    
    # VÃ©rifier le token d'accÃ¨s
    if kubectl get secret dashboard-admin-token -n kubernetes-dashboard --context "kind-${CLUSTER_NAME}" &> /dev/null; then
        log_success "ğŸ« Token d'accÃ¨s admin crÃ©Ã©"
    else
        log_warning "âš ï¸  Token d'accÃ¨s admin non trouvÃ©"
    fi
    
    return 0
}

# Test du pod curl
test_curl_pod() {
    log_info "ğŸ§ª === Test du pod curl ==="
    
    # VÃ©rifier que le pod curl existe et est prÃªt
    if kubectl get pod curl-test --context "kind-${CLUSTER_NAME}" &> /dev/null; then
        local pod_status=$(kubectl get pod curl-test --context "kind-${CLUSTER_NAME}" -o jsonpath='{.status.phase}')
        
        if [ "$pod_status" = "Running" ]; then
            log_success "âœ… Pod curl-test opÃ©rationnel"
            
            # Tester une requÃªte interne
            if kubectl exec curl-test --context "kind-${CLUSTER_NAME}" -- curl -s -o /dev/null -w "%{http_code}" \
                http://kubernetes-dashboard-kong-proxy.kubernetes-dashboard.svc.cluster.local 2>/dev/null | grep -q "200\|403\|404"; then
                log_success "ğŸŒ Pod curl peut accÃ©der aux services internes"
            else
                log_warning "âš ï¸  Pod curl ne peut pas accÃ©der aux services internes"
            fi
            
            # Tester l'accÃ¨s externe (DNS)
            if kubectl exec curl-test --context "kind-${CLUSTER_NAME}" -- curl -s -o /dev/null -w "%{http_code}" \
                https://httpbin.org/status/200 2>/dev/null | grep -q "200"; then
                log_success "ğŸŒ Pod curl a accÃ¨s Ã  Internet"
            else
                log_warning "âš ï¸  Pod curl n'a pas accÃ¨s Ã  Internet"
            fi
            
        else
            log_error "âŒ Pod curl-test non opÃ©rationnel (statut: $pod_status)"
            return 1
        fi
    else
        log_error "âŒ Pod curl-test non trouvÃ©"
        return 1
    fi
    
    return 0
}

# Test des certificats
test_certificates() {
    log_info "ğŸ”’ === Test des certificats ==="
    
    # VÃ©rifier le ClusterIssuer
    if kubectl get clusterissuer selfsigned-issuer --context "kind-${CLUSTER_NAME}" &> /dev/null; then
        log_success "âœ… ClusterIssuer selfsigned-issuer configurÃ©"
    else
        log_error "âŒ ClusterIssuer selfsigned-issuer non trouvÃ©"
        return 1
    fi
    
    # VÃ©rifier le certificat de test
    if kubectl get certificate test-certificate --context "kind-${CLUSTER_NAME}" &> /dev/null; then
        local cert_status=$(kubectl get certificate test-certificate --context "kind-${CLUSTER_NAME}" \
            -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "Unknown")
        
        if [ "$cert_status" = "True" ]; then
            log_success "ğŸ« Certificat de test valide et prÃªt"
        else
            log_warning "âš ï¸  Certificat de test en cours de crÃ©ation (statut: $cert_status)"
        fi
    else
        log_warning "âš ï¸  Certificat de test non trouvÃ©"
    fi
    
    return 0
}

# Test de connectivitÃ© complÃ¨te
test_connectivity() {
    log_info "ğŸ”— === Test de connectivitÃ© complÃ¨te ==="
    
    # Test depuis le pod curl vers le dashboard via l'ingress interne
    log_info "ğŸ§ª Test d'accÃ¨s au dashboard via ingress..."
    
    # Ajouter une entrÃ©e temporaire dans /etc/hosts du pod curl
    kubectl exec curl-test --context "kind-${CLUSTER_NAME}" -- sh -c "echo '127.0.0.1 dashboard.local' >> /etc/hosts" 2>/dev/null || true
    
    # Test d'accÃ¨s au dashboard (peut Ã©chouer si pas de /etc/hosts configurÃ© sur l'hÃ´te)
    local response=$(kubectl exec curl-test --context "kind-${CLUSTER_NAME}" -- \
        curl -s -o /dev/null -w "%{http_code}" http://dashboard.local 2>/dev/null || echo "000")
    
    if [ "$response" = "200" ] || [ "$response" = "403" ] || [ "$response" = "404" ]; then
        log_success "ğŸ¯ AccÃ¨s au dashboard via ingress fonctionnel (HTTP $response)"
    else
        log_warning "âš ï¸  AccÃ¨s au dashboard via ingress non fonctionnel (HTTP $response)"
        log_info "   Ajoutez '127.0.0.1 dashboard.local' Ã  /etc/hosts de l'hÃ´te"
    fi
    
    return 0
}

# Afficher le rÃ©sumÃ© des tests
show_test_summary() {
    local cert_manager_ok=$1
    local ingress_ok=$2
    local dashboard_ok=$3
    local curl_ok=$4
    local certificates_ok=$5
    
    log_info "ğŸ“Š === RÃ©sumÃ© des tests de configuration ==="
    [ "$cert_manager_ok" -eq 0 ] && log_success "âœ… cert-manager" || log_error "âŒ cert-manager"
    [ "$ingress_ok" -eq 0 ] && log_success "âœ… ingress-nginx (avec snippets)" || log_error "âŒ ingress-nginx"
    [ "$dashboard_ok" -eq 0 ] && log_success "âœ… Kubernetes Dashboard" || log_error "âŒ Kubernetes Dashboard"
    [ "$curl_ok" -eq 0 ] && log_success "âœ… Pod curl-test" || log_error "âŒ Pod curl-test"
    [ "$certificates_ok" -eq 0 ] && log_success "âœ… Certificats" || log_error "âŒ Certificats"
    
    echo ""
    if [ "$cert_manager_ok" -eq 0 ] && [ "$ingress_ok" -eq 0 ] && [ "$dashboard_ok" -eq 0 ] && [ "$curl_ok" -eq 0 ] && [ "$certificates_ok" -eq 0 ]; then
        log_success "ğŸ‰ Tous les composants avancÃ©s sont opÃ©rationnels !"
        echo "   âœ¨ Le cluster kind est complÃ¨tement configurÃ© et prÃªt Ã  l'emploi."
        echo ""
        log_info "ğŸŒ AccÃ¨s disponibles:"
        echo "   - Dashboard: http://dashboard.local"
        echo "   - Tests: kubectl exec -it curl-test -- sh"
        echo ""
        log_info "ğŸ”§ Configuration /etc/hosts requise:"
        echo "   echo '127.0.0.1 dashboard.local test.local' | sudo tee -a /etc/hosts"
    else
        log_error "ğŸ’¥ Certains composants ont des problÃ¨mes"
        echo "   ğŸ” VÃ©rifiez les logs ci-dessus pour diagnostiquer."
        echo "   ğŸ”§ Relancez la configuration: ./kind-config.sh ${CLUSTER_NAME}"
    fi
}

# Fonction principale
main() {
    log_info "ğŸ§ª === Tests de configuration avancÃ©e kind '${CLUSTER_NAME}' ==="
    echo ""
    
    # VÃ©rifier si le cluster existe
    if ! kind get clusters | grep -q "^${CLUSTER_NAME}$"; then
        log_error "âŒ Cluster kind '${CLUSTER_NAME}' non trouvÃ©"
        echo "   ğŸš€ CrÃ©ez le cluster avec ./start-kind.sh"
        exit 1
    fi
    
    local cert_manager_result=1
    local ingress_result=1
    local dashboard_result=1
    local curl_result=1
    local certificates_result=1
    
    # ExÃ©cuter les tests
    test_cert_manager && cert_manager_result=0
    echo ""
    
    test_ingress_nginx && ingress_result=0
    echo ""
    
    test_dashboard && dashboard_result=0
    echo ""
    
    test_curl_pod && curl_result=0
    echo ""
    
    test_certificates && certificates_result=0
    echo ""
    
    test_connectivity
    echo ""
    
    # Afficher le rÃ©sumÃ©
    show_test_summary $cert_manager_result $ingress_result $dashboard_result $curl_result $certificates_result
    
    # Code de sortie basÃ© sur les rÃ©sultats
    if [ "$cert_manager_result" -eq 0 ] && [ "$ingress_result" -eq 0 ] && [ "$dashboard_result" -eq 0 ] && [ "$curl_result" -eq 0 ] && [ "$certificates_result" -eq 0 ]; then
        exit 0
    else
        exit 1
    fi
}

# ExÃ©cuter le script principal
main "$@"
